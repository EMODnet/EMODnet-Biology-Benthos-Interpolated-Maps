{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to create the _benthos_ interpolated maps using `DIVAnd`.      \n",
    "The data file was prepared by P. Herman (Deltares)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Project.toml`\n",
      " \u001b[90m [efc8151c] \u001b[39m\u001b[37mDIVAnd v2.6.5\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using DIVAnd\n",
    "using PyPlot\n",
    "using Proj4\n",
    "using DelimitedFiles\n",
    "using PyCall\n",
    "using Dates\n",
    "using NCDatasets\n",
    "using Pkg\n",
    "include(\"../scripts/BenthosInterp.jl\")\n",
    "Pkg.status(\"DIVAnd\")\n",
    "\n",
    "doplot = false       # set to 'true' to create the plots\n",
    "doplotdata = true    # set to 'true' to plot the observations\n",
    "usecartopy = true    # set to 'true' if plots are created using Cartopy\n",
    "writenc = true;     # set to 'true' to write netCDF files with the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: File already downloaded\n",
      "└ @ Main In[2]:7\n"
     ]
    }
   ],
   "source": [
    "figdir = \"../product/figures/1-UniformL/\"\n",
    "outputdir = \"../product/netCDF/\"\n",
    "datadir = \"../data/\"\n",
    "datafile = joinpath(datadir, \"specs4Diva.csv\")\n",
    "isdir(figdir) ? \"Figure directory already exists\" : mkpath(figdir)\n",
    "isdir(outputdir) ? \"Output directory already exists\" : mkpath(outputdir)\n",
    "isfile(datafile) ? @info(\"File already downloaded\") : download(\"https://dox.ulg.ac.be/index.php/s/vNQcvqjW8RzdNBt/download\", datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain = [-16., 9., 45., 66.]; # [West East South North]\n",
    "Δlon = 0.1\n",
    "Δlat = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare mask\n",
    "### Interpolation grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.0:0.1:66.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longrid = domain[1]:Δlon:domain[2]\n",
    "latgrid = domain[3]:Δlat:domain[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download bathymetry file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Bathymetry file already downloaded\n",
      "└ @ Main In[5]:5\n"
     ]
    }
   ],
   "source": [
    "bathname = joinpath(datadir, \"gebco_30sec_4.nc\")\n",
    "if !isfile(bathname)\n",
    "    download(\"https://dox.ulg.ac.be/index.php/s/RSwm4HPHImdZoQP/download\", bathname)\n",
    "else\n",
    "    @info(\"Bathymetry file already downloaded\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read bathymetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(b) = (251, 211)\n"
     ]
    }
   ],
   "source": [
    "bx, by, b = load_bath(bathname, true, longrid, latgrid)\n",
    "@show size(b)\n",
    "\n",
    "if doplot\n",
    "    fig = PyPlot.figure()\n",
    "    ax = PyPlot.subplot(111)\n",
    "    pcolor(bx,by,b', vmin=0., cmap=PyPlot.cm.gist_earth); \n",
    "    colorbar(orientation=\"vertical\")\n",
    "    title(\"Depth (m)\")\n",
    "    savefig(joinpath(figdir, \"benthos_bathy.jpg\"), dpi=300, bbox_inches=\"tight\")\n",
    "    show()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (pm, pn),(xi, yi) = DIVAnd.DIVAnd_rectdom(longrid, latgrid);\n",
    "xi, yi, mask = DIVAnd.load_mask(bathname, true, longrid, latgrid, 0.0);\n",
    "xx, yy = ndgrid(xi, yi);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation\n",
    "### Data reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop on all the species: \n",
    "1. read the data\n",
    "2. compute the heatmaps and \n",
    "3. derive the probability field as:\n",
    "```\n",
    "d = npre * dens2 / (npre * dens_pre + nabs * dens_abs)\n",
    "```\n",
    "where \n",
    "* dens_pre is the heatmap obtained with the presence data only; \n",
    "* dens_abs is the heatmap obtained with the absence data only. \n",
    "\n",
    "The reason for this equation is that the heatmap are computed so that their integral over the domain is 1, whatever the number of observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set correlation length\n",
    "Lvalues = [0.01, 0.05, 0.1, 0.5, 1.]\n",
    "L = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "write_nc_error"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../scripts/BenthosInterp.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Abra_alba\n",
      "└ @ Main In[34]:6\n",
      "┌ Info: Working on species Abra_alba\n",
      "└ @ Main In[34]:7\n",
      "┌ Info: Column index for Abra_alba: 5\n",
      "└ @ Main /home/ctroupin/Projects/EMODnet/EMODnet-Biology-Benthos-Interpolated-Maps/scripts/BenthosInterp.jl:21\n",
      "┌ Info: Number of presence: 14068, number of absence: 65977\n",
      "└ @ Main In[34]:12\n"
     ]
    }
   ],
   "source": [
    "speciesnamelist = get_species_list(datafile)\n",
    "for species in speciesnamelist\n",
    "\n",
    "    speciesslug = get_species_slug(String(species))\n",
    "    \n",
    "    @info(speciesslug)\n",
    "    @info(\"Working on species $(String(species))\");\n",
    "    lon_pre, lat_pre, lon_abs, lat_abs = read_coords_species(datafile, species);\n",
    "    npre = length(lon_pre)\n",
    "    nabs = length(lon_abs)\n",
    "\n",
    "    @info(\"Number of presence: $(npre), number of absence: $(nabs)\")\n",
    "    \n",
    "\n",
    "    # Plot the data locations\n",
    "    if doplotdata\n",
    "        make_plot_presence_absence(lon_pre, lat_pre, lon_abs, lat_abs, String(species),\n",
    "            dlat=4., dlon=6.,\n",
    "            figname=joinpath(figdir, \"$(speciesslug)_data.jpg\"), usecartopy=true)\n",
    "    end\n",
    "    \n",
    "    \n",
    "    @info(\"Computing heatmaps\")\n",
    "    dens_pre, LHM2, LCV2, LSCV2 = DIVAnd_heatmap(mask, (pm,pn), (xx, yy), \n",
    "        (lon_pre, lat_pre), ones(npre), L);\n",
    "    dens_abs, LHM3, LCV3, LSCV3 = DIVAnd_heatmap(mask, (pm,pn), (xx, yy), \n",
    "        (lon_abs, lat_abs), ones(nabs), L);\n",
    "\n",
    "\n",
    "    d = npre .* dens_pre ./ (npre .* dens_pre .+ nabs .* dens_abs);\n",
    "\n",
    "    @info(\"Computing error field with CPME\")\n",
    "    lon = [lon_pre ; lon_abs]\n",
    "    lat = [lat_pre ; lat_abs]\n",
    "\n",
    "    cpme = DIVAnd_cpme(mask, (pm, pn), (xx, yy), (lon, lat), \n",
    "        ones(length(lon)), 0.5, 5.);\n",
    "\n",
    "    \n",
    "    if doplot\n",
    "        plot_heatmap(longrid, latgrid, d, lon_pre, lat_pre, lon_abs, lat_abs,\n",
    "            \"$(species): probability\", figname=joinpath(figdir, \"$(speciesslug)_density.jpßg\"), \n",
    "            usecartopy=usecartopy)            \n",
    "        #plot_error(longrid, latgrid, cpme, \"$(species)\", \n",
    "        #    joinpath(figdir, \"$(speciesslug)_error.png\"))\n",
    "    end   \n",
    "\n",
    "    if writenc\n",
    "        @info(\"Creating the netCDF file with results\")\n",
    "        create_nc_results(joinpath(outputdir, \"$(speciesslug)_density.nc\"), \n",
    "            longrid, latgrid, d, String(species), domain=domain);\n",
    "\n",
    "        @info(\"Adding error field to netCDF file\")\n",
    "        write_nc_error(joinpath(outputdir, \"$(speciesslug)_density.nc\"), cpme);\n",
    "    end\n",
    "\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"../product/netCDF/\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new field that takes into account the error field:\n",
    "* if error is zero, we take the gridded field as it is;\n",
    "* if error is close to 1, it means we don't have observations so the new field is zero (assuming that we don't have observations means there is nothing to observe);\n",
    "* if error is between 0 and 1, we calculate the field as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable correlation length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "defVar(ds::NCDataset,name,vtype,dimnames; kwargs...)\n",
       "defVar(ds::NCDataset,name,data,dimnames; kwargs...)\n",
       "\\end{verbatim}\n",
       "Define a variable with the name \\texttt{name} in the dataset \\texttt{ds}.  \\texttt{vtype} can be Julia types in the table below (with the corresponding NetCDF type). The parameter \\texttt{dimnames} is a tuple with the names of the dimension.  For scalar this parameter is the empty tuple \\texttt{()}. The variable is returned (of the type CFVariable).\n",
       "\n",
       "Instead of providing the variable type one can directly give also the data \\texttt{data} which will be used to fill the NetCDF variable. In this case, the dimensions with the appropriate size will be created as required using the names in \\texttt{dimnames}.\n",
       "\n",
       "If \\texttt{data} is a vector or array of \\texttt{DateTime} objects, then the dates are saved as double-precision floats and units \"days since 1900-01-01 00:00:00\" (unless a time unit is specifed with the \\texttt{attrib} keyword as described below). Dates are converted to the default calendar in the CF conversion which is the mixed Julian/Gregorian calendar.\n",
       "\n",
       "\\subsection{Keyword arguments}\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{fillvalue}: A value filled in the NetCDF file to indicate missing data.  It will be stored in the \\_FillValue attribute.\n",
       "\n",
       "\n",
       "\\item \\texttt{chunksizes}: Vector integers setting the chunk size. The total size of a chunk must be less than 4 GiB.\n",
       "\n",
       "\n",
       "\\item \\texttt{deflatelevel}: Compression level: 0 (default) means no compression and 9 means maximum compression. Each chunk will be compressed individually.\n",
       "\n",
       "\n",
       "\\item \\texttt{shuffle}: If true, the shuffle filter is activated which can improve the compression ratio.\n",
       "\n",
       "\n",
       "\\item \\texttt{checksum}: The checksum method can be \\texttt{:fletcher32} or \\texttt{:nochecksum} (checksumming is disabled, which is the default)\n",
       "\n",
       "\n",
       "\\item \\texttt{attrib}: An iterable of attribute name and attribute value pairs, for example a \\texttt{Dict}, \\texttt{DataStructures.OrderedDict} or simply a vector of pairs (see example below)\n",
       "\n",
       "\n",
       "\\item \\texttt{typename} (string): The name of the NetCDF type required for \\href{https://web.archive.org/save/https://www.unidata.ucar.edu/software/netcdf/netcdf-4/newdocs/netcdf-c/nc_005fdef_005fvlen.html}{vlen arrays}\n",
       "\n",
       "\\end{itemize}\n",
       "\\texttt{chunksizes}, \\texttt{deflatelevel}, \\texttt{shuffle} and \\texttt{checksum} can only be set on NetCDF 4 files.\n",
       "\n",
       "\\subsection{NetCDF data types}\n",
       "\\begin{tabular}\n",
       "{r | r}\n",
       "NetCDF Type & Julia Type \\\\\n",
       "\\hline\n",
       "NC\\_BYTE & Int8 \\\\\n",
       "NC\\_UBYTE & UInt8 \\\\\n",
       "NC\\_SHORT & Int16 \\\\\n",
       "NC\\_INT & Int32 \\\\\n",
       "NC\\_INT64 & Int64 \\\\\n",
       "NC\\_FLOAT & Float32 \\\\\n",
       "NC\\_DOUBLE & Float64 \\\\\n",
       "NC\\_CHAR & Char \\\\\n",
       "NC\\_STRING & String \\\\\n",
       "\\end{tabular}\n",
       "\\subsection{Example:}\n",
       "In this example, \\texttt{scale\\_factor} and \\texttt{add\\_offset} are applied when the \\texttt{data} is saved.\n",
       "\n",
       "\\begin{verbatim}\n",
       "julia> using DataStructures\n",
       "julia> data = randn(3,5)\n",
       "julia> NCDataset(\"test_file.nc\",\"c\") do ds\n",
       "          defVar(ds,\"temp\",data,(\"lon\",\"lat\"), attrib = OrderedDict(\n",
       "             \"units\" => \"degree_Celsius\",\n",
       "             \"add_offset\" => -273.15,\n",
       "             \"scale_factor\" => 0.1,\n",
       "             \"long_name\" => \"Temperature\"\n",
       "          ))\n",
       "       end;\n",
       "\\end{verbatim}\n",
       "\\begin{quote}\n",
       "\\textbf{note}\n",
       "\n",
       "Note\n",
       "\n",
       "If the attributes \\texttt{\\_FillValue}, \\texttt{add\\_offset}, \\texttt{scale\\_factor}, \\texttt{units} and \\texttt{calendar} are used, they should be defined when calling \\texttt{defVar} by using the parameter \\texttt{attrib} as shown in the example above.\n",
       "\n",
       "\\end{quote}\n"
      ],
      "text/markdown": [
       "```\n",
       "defVar(ds::NCDataset,name,vtype,dimnames; kwargs...)\n",
       "defVar(ds::NCDataset,name,data,dimnames; kwargs...)\n",
       "```\n",
       "\n",
       "Define a variable with the name `name` in the dataset `ds`.  `vtype` can be Julia types in the table below (with the corresponding NetCDF type). The parameter `dimnames` is a tuple with the names of the dimension.  For scalar this parameter is the empty tuple `()`. The variable is returned (of the type CFVariable).\n",
       "\n",
       "Instead of providing the variable type one can directly give also the data `data` which will be used to fill the NetCDF variable. In this case, the dimensions with the appropriate size will be created as required using the names in `dimnames`.\n",
       "\n",
       "If `data` is a vector or array of `DateTime` objects, then the dates are saved as double-precision floats and units \"days since 1900-01-01 00:00:00\" (unless a time unit is specifed with the `attrib` keyword as described below). Dates are converted to the default calendar in the CF conversion which is the mixed Julian/Gregorian calendar.\n",
       "\n",
       "## Keyword arguments\n",
       "\n",
       "  * `fillvalue`: A value filled in the NetCDF file to indicate missing data.  It will be stored in the _FillValue attribute.\n",
       "  * `chunksizes`: Vector integers setting the chunk size. The total size of a chunk must be less than 4 GiB.\n",
       "  * `deflatelevel`: Compression level: 0 (default) means no compression and 9 means maximum compression. Each chunk will be compressed individually.\n",
       "  * `shuffle`: If true, the shuffle filter is activated which can improve the compression ratio.\n",
       "  * `checksum`: The checksum method can be `:fletcher32` or `:nochecksum` (checksumming is disabled, which is the default)\n",
       "  * `attrib`: An iterable of attribute name and attribute value pairs, for example a `Dict`, `DataStructures.OrderedDict` or simply a vector of pairs (see example below)\n",
       "  * `typename` (string): The name of the NetCDF type required for [vlen arrays](https://web.archive.org/save/https://www.unidata.ucar.edu/software/netcdf/netcdf-4/newdocs/netcdf-c/nc_005fdef_005fvlen.html)\n",
       "\n",
       "`chunksizes`, `deflatelevel`, `shuffle` and `checksum` can only be set on NetCDF 4 files.\n",
       "\n",
       "## NetCDF data types\n",
       "\n",
       "| NetCDF Type | Julia Type |\n",
       "| -----------:| ----------:|\n",
       "|     NC_BYTE |       Int8 |\n",
       "|    NC_UBYTE |      UInt8 |\n",
       "|    NC_SHORT |      Int16 |\n",
       "|      NC_INT |      Int32 |\n",
       "|    NC_INT64 |      Int64 |\n",
       "|    NC_FLOAT |    Float32 |\n",
       "|   NC_DOUBLE |    Float64 |\n",
       "|     NC_CHAR |       Char |\n",
       "|   NC_STRING |     String |\n",
       "\n",
       "## Example:\n",
       "\n",
       "In this example, `scale_factor` and `add_offset` are applied when the `data` is saved.\n",
       "\n",
       "```julia-repl\n",
       "julia> using DataStructures\n",
       "julia> data = randn(3,5)\n",
       "julia> NCDataset(\"test_file.nc\",\"c\") do ds\n",
       "          defVar(ds,\"temp\",data,(\"lon\",\"lat\"), attrib = OrderedDict(\n",
       "             \"units\" => \"degree_Celsius\",\n",
       "             \"add_offset\" => -273.15,\n",
       "             \"scale_factor\" => 0.1,\n",
       "             \"long_name\" => \"Temperature\"\n",
       "          ))\n",
       "       end;\n",
       "```\n",
       "\n",
       "!!! note\n",
       "    If the attributes `_FillValue`, `add_offset`, `scale_factor`, `units` and `calendar` are used, they should be defined when calling `defVar` by using the parameter `attrib` as shown in the example above.\n",
       "\n"
      ],
      "text/plain": [
       "\u001b[36m  defVar(ds::NCDataset,name,vtype,dimnames; kwargs...)\u001b[39m\n",
       "\u001b[36m  defVar(ds::NCDataset,name,data,dimnames; kwargs...)\u001b[39m\n",
       "\n",
       "  Define a variable with the name \u001b[36mname\u001b[39m in the dataset \u001b[36mds\u001b[39m. \u001b[36mvtype\u001b[39m can be Julia\n",
       "  types in the table below (with the corresponding NetCDF type). The parameter\n",
       "  \u001b[36mdimnames\u001b[39m is a tuple with the names of the dimension. For scalar this\n",
       "  parameter is the empty tuple \u001b[36m()\u001b[39m. The variable is returned (of the type\n",
       "  CFVariable).\n",
       "\n",
       "  Instead of providing the variable type one can directly give also the data\n",
       "  \u001b[36mdata\u001b[39m which will be used to fill the NetCDF variable. In this case, the\n",
       "  dimensions with the appropriate size will be created as required using the\n",
       "  names in \u001b[36mdimnames\u001b[39m.\n",
       "\n",
       "  If \u001b[36mdata\u001b[39m is a vector or array of \u001b[36mDateTime\u001b[39m objects, then the dates are saved\n",
       "  as double-precision floats and units \"days since 1900-01-01 00:00:00\"\n",
       "  (unless a time unit is specifed with the \u001b[36mattrib\u001b[39m keyword as described below).\n",
       "  Dates are converted to the default calendar in the CF conversion which is\n",
       "  the mixed Julian/Gregorian calendar.\n",
       "\n",
       "\u001b[1m  Keyword arguments\u001b[22m\n",
       "\u001b[1m  ===================\u001b[22m\n",
       "\n",
       "    •    \u001b[36mfillvalue\u001b[39m: A value filled in the NetCDF file to indicate missing\n",
       "        data. It will be stored in the _FillValue attribute.\n",
       "\n",
       "    •    \u001b[36mchunksizes\u001b[39m: Vector integers setting the chunk size. The total size\n",
       "        of a chunk must be less than 4 GiB.\n",
       "\n",
       "    •    \u001b[36mdeflatelevel\u001b[39m: Compression level: 0 (default) means no compression\n",
       "        and 9 means maximum compression. Each chunk will be compressed\n",
       "        individually.\n",
       "\n",
       "    •    \u001b[36mshuffle\u001b[39m: If true, the shuffle filter is activated which can\n",
       "        improve the compression ratio.\n",
       "\n",
       "    •    \u001b[36mchecksum\u001b[39m: The checksum method can be \u001b[36m:fletcher32\u001b[39m or \u001b[36m:nochecksum\u001b[39m\n",
       "        (checksumming is disabled, which is the default)\n",
       "\n",
       "    •    \u001b[36mattrib\u001b[39m: An iterable of attribute name and attribute value pairs,\n",
       "        for example a \u001b[36mDict\u001b[39m, \u001b[36mDataStructures.OrderedDict\u001b[39m or simply a vector\n",
       "        of pairs (see example below)\n",
       "\n",
       "    •    \u001b[36mtypename\u001b[39m (string): The name of the NetCDF type required for vlen\n",
       "        arrays\n",
       "       \n",
       "      (https://web.archive.org/save/https://www.unidata.ucar.edu/software/netcdf/netcdf-4/newdocs/netcdf-c/nc_005fdef_005fvlen.html)\n",
       "\n",
       "  \u001b[36mchunksizes\u001b[39m, \u001b[36mdeflatelevel\u001b[39m, \u001b[36mshuffle\u001b[39m and \u001b[36mchecksum\u001b[39m can only be set on NetCDF 4\n",
       "  files.\n",
       "\n",
       "\u001b[1m  NetCDF data types\u001b[22m\n",
       "\u001b[1m  ===================\u001b[22m\n",
       "\n",
       "  NetCDF Type Julia Type\n",
       "  ––––––––––– ––––––––––\n",
       "      NC_BYTE       Int8\n",
       "     NC_UBYTE      UInt8\n",
       "     NC_SHORT      Int16\n",
       "       NC_INT      Int32\n",
       "     NC_INT64      Int64\n",
       "     NC_FLOAT    Float32\n",
       "    NC_DOUBLE    Float64\n",
       "      NC_CHAR       Char\n",
       "    NC_STRING     String\n",
       "\n",
       "\u001b[1m  Example:\u001b[22m\n",
       "\u001b[1m  ==========\u001b[22m\n",
       "\n",
       "  In this example, \u001b[36mscale_factor\u001b[39m and \u001b[36madd_offset\u001b[39m are applied when the \u001b[36mdata\u001b[39m is\n",
       "  saved.\n",
       "\n",
       "\u001b[36m  julia> using DataStructures\u001b[39m\n",
       "\u001b[36m  julia> data = randn(3,5)\u001b[39m\n",
       "\u001b[36m  julia> NCDataset(\"test_file.nc\",\"c\") do ds\u001b[39m\n",
       "\u001b[36m            defVar(ds,\"temp\",data,(\"lon\",\"lat\"), attrib = OrderedDict(\u001b[39m\n",
       "\u001b[36m               \"units\" => \"degree_Celsius\",\u001b[39m\n",
       "\u001b[36m               \"add_offset\" => -273.15,\u001b[39m\n",
       "\u001b[36m               \"scale_factor\" => 0.1,\u001b[39m\n",
       "\u001b[36m               \"long_name\" => \"Temperature\"\u001b[39m\n",
       "\u001b[36m            ))\u001b[39m\n",
       "\u001b[36m         end;\u001b[39m\n",
       "\n",
       "\u001b[36m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[36m\u001b[1mNote\u001b[22m\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  If the attributes \u001b[36m_FillValue\u001b[39m, \u001b[36madd_offset\u001b[39m, \u001b[36mscale_factor\u001b[39m, \u001b[36munits\u001b[39m and\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  \u001b[36mcalendar\u001b[39m are used, they should be defined when calling \u001b[36mdefVar\u001b[39m by\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  using the parameter \u001b[36mattrib\u001b[39m as shown in the example above."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?NCDatasets.defVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
